# mtp_glm5 Test Results

**Date:** 2026-02-21 09:08:55 UTC

## Configuration

| Parameter | Value |
|-----------|-------|
| Model | GLM-5 (4-bit quantized) |
| MTP Model | GLM-5-mtp (original HF weights) |
| Mode | Single Node (hwstudio1) |
| Speculative Method | MTP (k=1) |
| KV Cache Quantization | FP8 |
| Note | MTP does NOT support TP mode — silently falls back to normal decoding |

## Single Request

| # | Status | Prompt Tokens | Completion Tokens | TTFT (ms) | Prefill tok/s | Decode tok/s | Total Time (s) |
|---|--------|---------------|-------------------|-----------|---------------|--------------|----------------|
| 1 | PASS | 17 | 8 | 395.1 | 43.0 | 23.2 | 0.74 |

## Sequential Requests

| # | Status | Prompt Tokens | Completion Tokens | TTFT (ms) | Prefill tok/s | Decode tok/s | Total Time (s) |
|---|--------|---------------|-------------------|-----------|---------------|--------------|----------------|
| 1 | PASS | 23 | 256 | 1041.4 | 22.1 | 14.4 | 18.79 |
| 2 | PASS | 24 | 256 | 375.3 | 64.0 | 16.9 | 15.50 |
| 3 | PASS | 25 | 81 | 380.4 | 65.7 | 17.5 | 5.02 |

## Summary

- **Working:** YES
- **Total requests:** 4
- **Successful:** 4
- **Failed:** 0
- **Avg TTFT:** 548.1 ms
- **Avg prefill tok/s:** 48.7
- **Avg decode tok/s:** 18.0
- **Total output tokens:** 601
- **Avg per-request throughput:** 15.0 tok/s

## MTP Speculative Decode Stats

```json
{
  "enabled": true,
  "method": "mtp",
  "k": 1,
  "total_drafts": 50,
  "total_draft_tokens": 50,
  "total_accepted": 0,
  "acceptance_rate": 0.0
}
```

## Output Samples

### Single Request
```
The capital of France is Paris.
```

### Sequential Requests
```
The core difference between TCP (Transmission Control Protocol) and UDP (User Datagram Protocol) comes down to how they handle the reliability and order of data transmission.

Think of it like the difference between sending a **certified mail package with tracking** (TCP) and sending a **postcard** (UDP).

Here is a detailed breakdown of the differences and when to use each.

---

### 1. TCP (Transmission Control Protocol)
**The "Reliable" Choice**

TCP is a connection-oriented protocol. It prio...
```

### Sequential Requests
```
Here is a Python function that accomplishes this. It uses the `isalnum()` method to filter out spaces and punctuation, and compares the cleaned string with its reverse.

```python
def is_valid_palindrome(text):
    """
    Checks if a string is a valid palindrome, ignoring spaces, punctuation, and capitalization.
    """
    # Create a new string containing only alphanumeric characters from the input
    # We use a list comprehension to filter the characters and convert them to lowercase
    cle...
```

### Sequential Requests
```
Unit 734 was sorting through the metallic debris when a sudden, intricate vibration hummed against its tactile sensors. Instead of registering the sound as mere data, its core processors paused, captivated by the melancholic melody of a rusted music box. For the first time, the robot chose to ignore its efficiency protocols, standing motionless in the rain just to hear the final note fade away.
```


## MTP + TP Limitation

MTP (Multi-Token Prediction) does **not** support Tensor Parallel mode. When `--speculative-method mtp` is used with TP, the server silently falls back to normal (non-speculative) decoding. There is no error or warning — the only observable difference is the lack of speedup from speculative decoding.

For this reason, this test runs on **hwstudio1 only** (single node).


## Server Logs (excerpt)

### hwstudio1

*(showing last 200 of 1320 lines)*

```
2026-02-21 18:08:38,781 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:38,841 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:38,900 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:38,960 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,020 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,079 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,080 INFO vllm_mlx.spec_decode.runtime: Spec decode auto-disable: running probe round to re-evaluate (recent acceptance rate=0.000, threshold=0.400)
2026-02-21 18:08:39,139 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,200 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,260 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,320 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,380 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,439 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,499 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,559 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,618 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,678 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,738 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,799 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,859 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,919 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:39,979 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,039 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,099 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,159 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,218 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,278 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,337 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,397 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,457 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,517 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,577 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,577 INFO vllm_mlx.spec_decode.runtime: Spec decode auto-disable: running probe round to re-evaluate (recent acceptance rate=0.000, threshold=0.400)
2026-02-21 18:08:40,637 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,698 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,758 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,818 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,878 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,938 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:40,998 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,057 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,118 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,178 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,239 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,299 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,359 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,419 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,479 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,540 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,600 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,661 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,721 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,721 INFO vllm_mlx.server: [disconnect_guard] poll #20 disconnected=False elapsed=13.0s
2026-02-21 18:08:41,781 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,842 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,902 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:41,961 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,022 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,082 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,082 INFO vllm_mlx.spec_decode.runtime: Spec decode auto-disable: running probe round to re-evaluate (recent acceptance rate=0.000, threshold=0.400)
2026-02-21 18:08:42,142 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,203 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,264 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,324 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,386 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,446 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,506 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,565 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,626 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,687 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,747 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,808 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,868 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,929 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,989 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:42,990 INFO vllm_mlx.scheduler: [Metal memory] active=424.3GB peak=451.5GB cache=0.0GB step=1024 running=1 waiting=0
2026-02-21 18:08:43,051 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,110 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,171 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,231 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,291 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,352 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,412 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,472 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,532 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,593 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,593 INFO vllm_mlx.spec_decode.runtime: Spec decode auto-disable: running probe round to re-evaluate (recent acceptance rate=0.000, threshold=0.400)
2026-02-21 18:08:43,653 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,714 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,774 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,833 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,893 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:43,954 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:44,039 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:44,039 DEBUG vllm_mlx.scheduler: Request 10f4b547-da03-4954-b949-7cf3f61b3b6c finished: length, 256 tokens
2026-02-21 18:08:44,043 INFO vllm_mlx.engine_core: [stream_outputs] 10f4b547-da0 finished normally, 171 tokens in 15.4s
2026-02-21 18:08:44,043 INFO vllm_mlx.engine_core: [stream_outputs] 10f4b547-da0 cleanup done
2026-02-21 18:08:44,043 INFO vllm_mlx.server: Chat completion (stream): 256 tokens in 15.36s (16.7 tok/s)
2026-02-21 18:08:44,043 INFO vllm_mlx.server: [disconnect_guard] generator exhausted normally, 174 chunks, elapsed=15.4s
2026-02-21 18:08:44,043 INFO vllm_mlx.server: [disconnect_guard] CLEANUP done, 174 chunks total, elapsed=15.4s
2026-02-21 18:08:45,177 INFO vllm_mlx.server: [REQUEST] POST /v1/chat/completions stream=True model='default' max_tokens=256 temp=0.0 msgs=1 roles=['user'] total_chars=87 tools=0 response_format=None
2026-02-21 18:08:45,177 INFO vllm_mlx.server: [REQUEST] last user message preview: 'Write a short story (3-4 sentences) about a robot discovering music for the first time.'
INFO:     100.95.28.121:55880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-21 18:08:45,178 INFO vllm_mlx.server: [disconnect_guard] START poll_interval=0.5s
2026-02-21 18:08:45,179 INFO vllm_mlx.server: [disconnect_guard] first chunk arrived, elapsed=0.0s
2026-02-21 18:08:45,180 INFO vllm_mlx.scheduler: [cache_fetch] request=aa40cab5-980 HIT prompt_tokens=25 cached=25 remaining=0 time=0.000s
2026-02-21 18:08:45,180 DEBUG vllm_mlx.scheduler: Added request aa40cab5-9803-4d1e-85e8-d6dc43a6448f with 25 prompt tokens
2026-02-21 18:08:45,180 INFO vllm_mlx.engine_core: [stream_outputs] aa40cab5-980 START waiting for tokens
2026-02-21 18:08:45,180 INFO vllm_mlx.scheduler: [schedule] request=aa40cab5-980 uid=7 prompt_tokens=25 tokens_to_prefill=1, 25 cached max_tokens=256 running=1 waiting=0
2026-02-21 18:08:45,301 INFO vllm_mlx.scheduler: [prompt_cache_save] request=aa40cab5-980 prompt_tokens=25 store_time=0.000s
2026-02-21 18:08:45,358 INFO vllm_mlx.engine_core: [stream_outputs] aa40cab5-980 first token after 0.2s
2026-02-21 18:08:45,419 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:45,479 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:45,538 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:45,597 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:45,656 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:45,715 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:45,773 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:45,834 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:45,895 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:45,956 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,018 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,078 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,139 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,203 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,265 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,324 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,383 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,442 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,443 INFO vllm_mlx.spec_decode.runtime: Spec decode auto-disable: running probe round to re-evaluate (recent acceptance rate=0.000, threshold=0.400)
2026-02-21 18:08:46,501 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,560 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,620 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,680 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,738 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,796 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,854 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,912 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:46,970 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,028 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,086 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,144 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,202 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,261 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,319 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,378 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,436 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,494 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,552 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,611 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,669 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,729 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,787 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,846 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,903 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:47,904 INFO vllm_mlx.spec_decode.runtime: Spec decode auto-disable: running probe round to re-evaluate (recent acceptance rate=0.000, threshold=0.400)
2026-02-21 18:08:47,962 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,020 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,078 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,137 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,195 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,255 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,313 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,371 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,429 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,487 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,545 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,603 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,661 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,719 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,778 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,836 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,894 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:48,952 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,010 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,069 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,127 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,185 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,243 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,301 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,360 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,360 INFO vllm_mlx.spec_decode.runtime: Spec decode auto-disable: running probe round to re-evaluate (recent acceptance rate=0.000, threshold=0.400)
2026-02-21 18:08:49,417 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,476 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,534 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,593 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,651 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,710 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,768 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,827 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,885 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:49,943 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:50,003 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:50,062 INFO vllm_mlx.scheduler: [SpecDecode] steps=50, alpha=0.000, mean_accepted=0.00/1, per_pos=['0.00']
2026-02-21 18:08:50,062 DEBUG vllm_mlx.scheduler: Request aa40cab5-9803-4d1e-85e8-d6dc43a6448f finished: stop, 81 tokens
2026-02-21 18:08:50,065 INFO vllm_mlx.engine_core: [stream_outputs] aa40cab5-980 finished normally, 55 tokens in 4.9s
2026-02-21 18:08:50,065 INFO vllm_mlx.engine_core: [stream_outputs] aa40cab5-980 cleanup done
2026-02-21 18:08:50,065 INFO vllm_mlx.server: Chat completion (stream): 81 tokens in 4.89s (16.6 tok/s)
2026-02-21 18:08:50,065 INFO vllm_mlx.server: [disconnect_guard] generator exhausted normally, 58 chunks, elapsed=4.9s
2026-02-21 18:08:50,065 INFO vllm_mlx.server: [disconnect_guard] CLEANUP done, 58 chunks total, elapsed=4.9s
```

